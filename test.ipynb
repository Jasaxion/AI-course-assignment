{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"我来到了北京清华大学。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 来到 了 北京 清华大学 。\n",
      "我 来到 了 北京 清华大学 。\n"
     ]
    }
   ],
   "source": [
    "#测试一下FMM/BMM\n",
    "from algorithm.FMM_BMM import FMM_BMM\n",
    "import os\n",
    "from utils.utils import load_dictionary\n",
    "dataset_path = './dataset/icwb2-data'\n",
    "training_file = os.path.join(dataset_path, 'gold/msr_training_words.utf8')\n",
    "dictionary = load_dictionary(training_file)\n",
    "fmm_bmm = FMM_BMM(dictionary)\n",
    "\n",
    "fmm = ' '.join(fmm_bmm.forward_max_matching(text))\n",
    "bmm = ' '.join(fmm_bmm.backward_max_matching(text))\n",
    "\n",
    "print(fmm)\n",
    "print(bmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我来 到 了 北京 清华 大学 。\n"
     ]
    }
   ],
   "source": [
    "#测试一下 HMM\n",
    "from algorithm.HMM import HMMTokenizer\n",
    "hmm_tokenizer = HMMTokenizer()\n",
    "model_dir = \"/home/shaoxiong/exa/人工智能大作业/algorithm/model/HMM\"\n",
    "hmm_tokenizer.load_model(model_dir)\n",
    "\n",
    "hmm = ' '.join(hmm_tokenizer.tokenize(text))\n",
    "print(hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我来到 了北京 清华大学。\n"
     ]
    }
   ],
   "source": [
    "#测试一下N-gram\n",
    "from algorithm.NGram import NgramTokenizer\n",
    "ngram_tokenizer = NgramTokenizer()\n",
    "model_dir = \"/home/shaoxiong/exa/人工智能大作业/algorithm/model/N-Gram\"\n",
    "ngram_tokenizer.load_model(model_dir)\n",
    "\n",
    "ngram = ' '.join(ngram_tokenizer.tokenize(text))\n",
    "print(ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们 班 的 同 学 都 到 了 学 校 。\n"
     ]
    }
   ],
   "source": [
    "#测试一下RNN\n",
    "from algorithm.RNN import RNNSegmentation\n",
    "import torch\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.char_to_idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "        self.idx_to_char = {0: '<PAD>', 1: '<UNK>'}\n",
    "        self.tag_to_idx = {'<PAD>': 0, 'B': 1, 'M': 2, 'E': 3, 'S': 4}\n",
    "        self.idx_to_tag = {0: '<PAD>', 1: 'B', 2: 'M', 3: 'E', 4: 'S'}\n",
    "        \n",
    "    def add_character(self, char: str):\n",
    "        if char not in self.char_to_idx:\n",
    "            idx = len(self.char_to_idx)\n",
    "            self.char_to_idx[char] = idx\n",
    "            self.idx_to_char[idx] = char\n",
    "            \n",
    "    def get_vocab_size(self) -> int:\n",
    "        return len(self.char_to_idx)\n",
    "    \n",
    "    def get_tag_size(self) -> int:\n",
    "        return len(self.tag_to_idx)\n",
    "vocab = Vocabulary()\n",
    "rnn_model = RNNSegmentation(5169, \n",
    "                          vocab.get_tag_size(),\n",
    "                          embedding_dim=128,\n",
    "                          hidden_dim=256)\n",
    "ckpj = torch.load(\"/home/shaoxiong/exa/人工智能大作业/algorithm/model/RNN-based/rnn_segmentation_model.pt\")\n",
    "rnn_model.load_state_dict(ckpj['model_state_dict'])\n",
    "rnn_model.eval()\n",
    "from algorithm.RNN import segment_text\n",
    "rnn = ' '.join(segment_text(rnn_model.to('cuda'), text, vocab))\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们 班 的 同学 都 到 了 学校 。\n"
     ]
    }
   ],
   "source": [
    "#测试BiLSTM\n",
    "from algorithm.BiLSTM import BiLSTMSegmentation,segment_text\n",
    "bilstm_model = BiLSTMSegmentation(5169, \n",
    "                             vocab.get_tag_size(),\n",
    "                             embedding_dim=256,  # 增大embedding维度\n",
    "                             hidden_dim=512)\n",
    "ckpj = torch.load(\"/home/shaoxiong/exa/人工智能大作业/algorithm/model/BiLSTM-based/bilstm_segmentation_model.pt\")\n",
    "bilstm_model.load_state_dict(ckpj['model_state_dict'])\n",
    "bilstm_model.eval()\n",
    "bilstm = ' '.join(segment_text(bilstm_model.to('cuda'), text, vocab))\n",
    "print(bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们 班的 同 学都 到 了 学校 。\n"
     ]
    }
   ],
   "source": [
    "#测试Transformers\n",
    "from algorithm.Transformers import ChineseSegmentationTransformer,segment_text\n",
    "\n",
    "ckpj = torch.load(\"/home/shaoxiong/exa/人工智能大作业/algorithm/model/Transformers-based/chinese_segmentation_transformer.pt\")\n",
    "vocab = ckpj['vocab']\n",
    "model_config = ckpj['model_config']\n",
    "transformer_model = ChineseSegmentationTransformer(\n",
    "        vocab_size=vocab.get_vocab_size(),\n",
    "        tag_size=vocab.get_tag_size(),\n",
    "        d_model=128,  # 减小模型维度\n",
    "        num_heads=4,  # 减少注意力头数\n",
    "        num_layers=4,  # 减少层数\n",
    "        d_ff=512,     # 减小前馈网络维度\n",
    "        dropout=0.2   # 增加dropout\n",
    "    )\n",
    "transformer_model.load_state_dict(ckpj['model_state_dict'])\n",
    "transformer_model.eval()\n",
    "text=\"我们班的同学都到了学校。\"\n",
    "transformer = ' '.join(segment_text(transformer_model.to('cuda'), text, vocab))\n",
    "print(transformer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
